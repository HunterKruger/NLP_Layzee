{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from model import Albert\n",
    "from dataset import CustomDataset, process_data, train_test_split\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from time import time \n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AlbertForSequenceClassification\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.CUDA_VISIBLE_DEVICES      # specify GPU usage    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    return acc\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Training set shape: (11391, 3)\n",
      "Validaiton set shape: (2847, 3)\n",
      "Loading finished.\n",
      "Processing dataset...\n",
      "Processing finished.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    ## Loading data\n",
    "    print('Loading dataset...')\n",
    "    if config.ALREADY_SPLIT:\n",
    "        train_df = pd.read_csv(config.TRAIN_FILE) \n",
    "        val_df = pd.read_csv(config.VALIDATION_FILE)    \n",
    "        print('Training set shape: '+ str(train_df.shape))\n",
    "        print('Validaiton set shape: '+ str(val_df.shape))\n",
    "        print('Loading finished.')\n",
    "    else:\n",
    "        data_df = process_data(config.INPUT_FILE, config.CLS2IDX, True)     # DataFrame, only used labeled data\n",
    "        train_df, test_df = train_test_split(\n",
    "            data_df, \n",
    "            test_size=config.TEST_SIZE, \n",
    "            shuffle=True, \n",
    "            random_state=config.RANDOM_STATE)\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df, \n",
    "            test_size=config.VALIDATION_SIZE, \n",
    "            shuffle=True, \n",
    "            random_state=config.RANDOM_STATE)  \n",
    "        print('Training set shape: '+ str(train_df.shape))\n",
    "        print('Validaiton set shape: '+ str(val_df.shape))\n",
    "        print('Test set shape: '+ str(test_df.shape))\n",
    "        print('Loading finished.')\n",
    "        print('Saving training set & validation set & test set to local...')\n",
    "        train_df.to_csv(config.TRAIN_FILE, index=False)\n",
    "        val_df.to_csv(config.VALIDATION_FILE, index=False)\n",
    "        test_df.to_csv(config.TEST_FILE, index=False)\n",
    "        print('Saving finished.')\n",
    "    \n",
    "\n",
    "    ## Processing data\n",
    "    print('Processing dataset...')\n",
    "    train_set = CustomDataset(\n",
    "        sentences=train_df[config.CONTENT_FIELD].values.astype(\"str\"),\n",
    "        labels=train_df[config.LABEL_FIELD]\n",
    "    )\n",
    "    val_set = CustomDataset(\n",
    "        sentences=val_df[config.CONTENT_FIELD].values.astype(\"str\"),\n",
    "        labels=val_df[config.LABEL_FIELD]\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_set, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset=val_set, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print('Processing finished.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_ids': tensor([ 101, 5307, 5317, 3221,  679, 2100, 1762, 4638, 8024, 3187, 6389,  872,\n",
       "         4500, 3227, 2544, 7262, 4692, 8024, 6820, 3221,  166, 1045, 4212, 8024,\n",
       "         6963, 4692,  679, 6224,  511, 5307, 5317,  510, 4954,  855, 3221,  704,\n",
       "         1744, 1367,  782, 1762,  679, 5543, 1059, 7481, 6371, 6399,  782,  860,\n",
       "         4638, 2658, 1105,  678, 5621, 2682, 1139, 3341, 4638,  691, 6205, 8024,\n",
       "         5445, 6821, 3315,  841, 4906, 2110, 4638,  741, 6820, 1762, 1920, 1297,\n",
       "         8024, 1938, 1214, 1920, 2157, 6206,  676, 2590,  511,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]),\n",
       " 'attention_masks': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'labels': tensor(2)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8063a049ce6126424592ab63ae068ec0717401a263e6cd39dbb78c77b7761238"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('transformers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
