{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Training set shape: (11391, 3)\n",
      "Validaiton set shape: (2847, 3)\n",
      "Loading finished.\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from dataset import CustomDataset, process_data, train_test_split\n",
    "from model import create_model\n",
    "\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.CUDA_VISIBLE_DEVICES    # specify GPU usage    \n",
    "\n",
    "\n",
    "print('Loading dataset...')\n",
    "train_df = pd.read_csv(config.TRAIN_FILE) \n",
    "val_df = pd.read_csv(config.VALIDATION_FILE)    \n",
    "print('Training set shape: '+ str(train_df.shape))\n",
    "print('Validaiton set shape: '+ str(val_df.shape))\n",
    "print('Loading finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Processing finished.\n"
     ]
    }
   ],
   "source": [
    "print('Processing dataset...')\n",
    "train_set = CustomDataset(\n",
    "    sentences=train_df[config.CONTENT_FIELD].values.astype(\"str\"),\n",
    "    labels=train_df[config.LABEL_FIELD],\n",
    "    batch_size=config.BATCH_SIZE\n",
    ")\n",
    "val_set = CustomDataset(\n",
    "    sentences=val_df[config.CONTENT_FIELD].values.astype(\"str\"),\n",
    "    labels=val_df[config.LABEL_FIELD],\n",
    "    batch_size=config.BATCH_SIZE\n",
    ")\n",
    "print('Processing finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(196,), dtype=int32, numpy=\n",
       "array([  101,  2595,   817,  3683,  7770,  8024,  1912,  6225,  4692,\n",
       "        4708,  7556,  4706,  8024,  6421,  3300,  4638,  1216,  5543,\n",
       "        6963,  3300,   749,  8024,  2897,  1168,  4638,  3221,  2130,\n",
       "        5401,  2242,  8024,  2458,  2552, 10139,   102,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(196,), dtype=int32, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0][0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(196,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0][0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '20211013-114803-04__20211013-122045-04.index', 2: '20211013-114803-04.index'}\n",
      "Initializing model...\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ../../experiments/model/bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../../experiments/model/bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8b5dba2458>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f8b5d3a85c0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8b5dba2458>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f8b5d3a85c0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Init model from a checkpoint...\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 196)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 196)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 196)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertModel)              TFBaseModelOutputWit 102267648   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "                                                                 token_type_ids[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_0 (GlobalMaxPooling1D)  (None, 768)          0           bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_1 (GlobalMaxPooling1D)  (None, 768)          0           bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_2 (GlobalMaxPooling1D)  (None, 768)          0           bert[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_3 (GlobalMaxPooling1D)  (None, 768)          0           bert[0][3]                       \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 3072)         0           maxpool_0[0][0]                  \n",
      "                                                                 maxpool_1[0][0]                  \n",
      "                                                                 maxpool_2[0][0]                  \n",
      "                                                                 maxpool_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3072)         0           concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 3)            9219        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 102,276,867\n",
      "Trainable params: 102,276,867\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Initialization finished.\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from dataset import CustomDataset, process_data, train_test_split\n",
    "from model import create_model\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers.optimization_tf import create_optimizer\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "## Model init\n",
    "filenames = dict()\n",
    "i = 1\n",
    "for f in os.listdir(config.ROOT_PATH):\n",
    "    if '.index' in f:\n",
    "        filenames[i] = f\n",
    "        i+=1\n",
    "print(filenames)\n",
    "get_epoch = input('Choose a checkpoint (input 0 to train a new model):')\n",
    "get_epoch = int(get_epoch)\n",
    "\n",
    "print('Initializing model...')\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()     # multi-GPU config\n",
    "with mirrored_strategy.scope():\n",
    "    model = create_model()\n",
    "    if get_epoch == 0:     \n",
    "        print('Init a new model...')\n",
    "        checkpoint_path = config.ROOT_PATH + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'-{epoch:02d}'                 # save the model checkpoints\n",
    "        optimizer, lr_schedule = create_optimizer(\n",
    "            init_lr=config.ADAM_LR, \n",
    "            num_train_steps=math.ceil(train_df.shape[0]/config.EPOCHS)*config.EPOCHS,\n",
    "            num_warmup_steps=config.ADAM_WARMUP_STEPS,\n",
    "            min_lr_ratio=config.ADAM_MIN_LR_RATIO,\n",
    "            weight_decay_rate=config.ADAM_DECAY_RATE,\n",
    "            power=config.ADAM_POWER\n",
    "        )\n",
    "        metric = SparseCategoricalAccuracy()\n",
    "        loss = SparseCategoricalCrossentropy()\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    else:\n",
    "        print('Init model from a checkpoint...')\n",
    "        checkpoint_path = config.ROOT_PATH + filenames[get_epoch].replace('.index','') + '__' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '-{epoch:02d}' # save the model checkpoints\n",
    "        model.load_weights(config.ROOT_PATH + filenames[get_epoch].replace('.index','')).expect_partial()\n",
    "        lr_schedule = ExponentialDecay(\n",
    "            config.SGD_LR,\n",
    "            decay_steps=config.SGD_DECAY_STEPS,\n",
    "            decay_rate=config.SGD_DECAY_RATE\n",
    "        )\n",
    "        optimizer = SGD(\n",
    "            learning_rate=lr_schedule, \n",
    "            momentum=config.SGD_MOMENTUM, \n",
    "            nesterov=config.SGD_NESTEROV\n",
    "        )           \n",
    "        metric = SparseCategoricalAccuracy()\n",
    "        loss = SparseCategoricalCrossentropy()\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "model.summary()\n",
    "print('Initialization finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f8afff9f2b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('bert')._layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087872"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('bert')._layers[0]._layers[1]._layers[0][2].count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertPooler at 0x7f8a9be7f198>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('bert')._layers[0]._layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fengyuan/workspaceGServer/NLP/sentiment_analysis_bert/code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8063a049ce6126424592ab63ae068ec0717401a263e6cd39dbb78c77b7761238"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('transformers': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
