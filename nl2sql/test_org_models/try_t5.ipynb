{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/home/fengyuan/anaconda3/envs/transformers/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:664: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "path = \"../experiments/model/t5-base-finetuned-wikiSQL\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelWithLMHead.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(query):\n",
    "  input_text = \"translate English to SQL: %s </s>\" % query\n",
    "  features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=features['input_ids'], \n",
    "               attention_mask=features['attention_mask'])\n",
    "  \n",
    "  return tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> SELECT COUNT Model fine tuned FROM table WHERE Base model = BERT</s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many models were finetuned using BERT as base model?\"\n",
    "\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> SELECT COUNT Population FROM table WHERE City = Shanghai</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many people are there is Shanghai?\"\n",
    "\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> SELECT COUNT Number FROM table WHERE Age > 50 AND City = s'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"How many people in Shanghai are older than 50?\"\n",
    "\n",
    "get_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/home/fengyuan/anaconda3/envs/transformers/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:664: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "\n",
    "class Text2SQL:\n",
    "\n",
    "    def __init__(self, t5_path, mt_path):\n",
    "        self.tokenizer_t5 = AutoTokenizer.from_pretrained(t5_path)\n",
    "        self.model_t5 = AutoModelWithLMHead.from_pretrained(t5_path)\n",
    "        self.tokenizer_mt = AutoTokenizer.from_pretrained(mt_path)\n",
    "        self.model_mt = AutoModelForSeq2SeqLM.from_pretrained(mt_path)\n",
    "\n",
    "    def zh2en(self, sentence):\n",
    "        self.tokenizer_mt.padding_side = \"left\"\n",
    "        self.tokenizer_mt.pad_token = self.tokenizer_mt.eos_token # to avoid an error\n",
    "        task_prefix = 'translate Chinese to English: '\n",
    "        inputs = self.tokenizer_mt(task_prefix + sentence, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        output_sequences = self.model_mt.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            do_sample=False, # disable sampling to test if batching affects output\n",
    "        )\n",
    "   \n",
    "\n",
    "        result = self.tokenizer_mt.batch_decode(output_sequences, skip_special_tokens=True)[0]\n",
    "        result = result.replace('<pad>','')\n",
    "        result = result.strip()\n",
    "        return result\n",
    "\n",
    "    def text2sql(self, query):\n",
    "        input_text = \"translate English to SQL: %s </s>\" % query\n",
    "        features = self.tokenizer_t5([input_text], return_tensors='pt')\n",
    "        output = self.model_t5.generate(input_ids=features['input_ids'], attention_mask=features['attention_mask'])\n",
    "        result = self.tokenizer_t5.decode(output[0])\n",
    "        result = result.replace('<pad>','')\n",
    "        result = result.strip()\n",
    "        return result\n",
    "\n",
    "    def do_inference(self, input_sent, table_id):\n",
    "        result = self.zh2en(input_sent)\n",
    "        result = self.text2sql(result)\n",
    "        result = result.replace('</s>','')\n",
    "        result = result.replace('table', table_id)\n",
    "        return result\n",
    "\n",
    "t5_path =  \"../experiments/model/t5-base-finetuned-wikiSQL\"\n",
    "mt_path =  \"../experiments/model/opus-mt-zh-en\"\n",
    "text2sql = Text2SQL(t5_path,mt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT Population FROM 123124 WHERE City = Shanghai\n"
     ]
    }
   ],
   "source": [
    "query = '上海有多少人口？'\n",
    "table_id = '123124'\n",
    "\n",
    "print(text2sql.do_inference(query, table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MAX City FROM fsadf WHERE Country = united states\n"
     ]
    }
   ],
   "source": [
    "query = '美国最大的城市是哪个？'\n",
    "table_id = 'fsadf'\n",
    "\n",
    "print(text2sql.do_inference(query, table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8063a049ce6126424592ab63ae068ec0717401a263e6cd39dbb78c77b7761238"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('transformers': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
