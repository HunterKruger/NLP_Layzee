{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from model import MSQL\n",
    "from dataset import CustomDataset, collate_fn\n",
    "from utils import read_data, read_tables\n",
    "\n",
    "import os \n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "from time import time \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config.CUDA_VISIBLE_DEVICES      # specify GPU usage  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "41522 samples and 5013 tables in the training set\n",
      "4396 samples and 1197 tables in the validation set\n",
      "Loading finished.\n",
      "Creating dataset...\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "print('Loading data...')\n",
    "train_tables = read_tables(config.train_table_file)\n",
    "train_data = read_data(config.train_data_file, train_tables)\n",
    "val_tables = read_tables(config.val_table_file)\n",
    "val_data = read_data(config.val_data_file, val_tables)\n",
    "print(f'{len(train_data)} samples and {len(train_tables)} tables in the training set')\n",
    "print(f'{len(val_data)} samples and {len(val_tables)} tables in the validation set')\n",
    "print('Loading finished.')\n",
    "\n",
    "### Create dataset\n",
    "print('Creating dataset...')\n",
    "train_set = CustomDataset(train_data)\n",
    "val_set = CustomDataset(val_data)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_set, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_set, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 36912, 1: 4607, 2: 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_num = {0:0, 1:0, 2:0}\n",
    "for sample in train_set:\n",
    "    label = sample['S_num'].item()\n",
    "    S_num[label]+=1\n",
    "S_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8557, 2: 15542, 0: 16429, 4: 754, 3: 201, 6: 36, 5: 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_num_op = dict()\n",
    "for sample in train_set:\n",
    "    label = sample['W_num_op'].item()\n",
    "    if label in W_num_op.keys():\n",
    "        W_num_op[label]+=1\n",
    "    else:\n",
    "        W_num_op[label]=1\n",
    "W_num_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'NULL-1',\n",
       "  1: 'OR-2',\n",
       "  2: 'AND-2',\n",
       "  3: 'OR-3',\n",
       "  4: 'AND-3',\n",
       "  5: 'OR-4',\n",
       "  6: 'AND-4'},\n",
       " {0: 1, 1: 2, 2: 3})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.W_num_op_id2label, config.S_num_id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36876\n"
     ]
    }
   ],
   "source": [
    "new_train_data = []\n",
    "\n",
    "for idx, sample in enumerate(train_data):\n",
    "    W_num_op_label = sample.sql.conn_sql_dict[sample.sql.cond_conn_op] + '-' + str(len(sample.sql.conds)) \n",
    "    S_num_label = len(sample.sql.sel)\n",
    "    if S_num_label!=2 and W_num_op_label!='OR-4' and W_num_op_label!='AND-4' :\n",
    "        new_train_data.append(sample)\n",
    "\n",
    "print(len(new_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "sel: [2]<br>agg: ['SUM']<br>cond_conn_op: 'OR'<br>conds: [[0, '==', '大黄蜂'], [0, '==', '密室逃生']]"
      ],
      "text/plain": [
       "sel: [2]\n",
       "agg: ['SUM']\n",
       "cond_conn_op: 'OR'\n",
       "conds: [[0, '==', '大黄蜂'], [0, '==', '密室逃生']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x.repeat(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4, 4)\n",
    "\n",
    "torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_acc(logits, target, mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: (batch, max_headers, num_classes),  not yet passed to Softmax \n",
    "        target: (batch, max_headers) \n",
    "        mask  : (batch_size, max_headers)\n",
    "\n",
    "    \"\"\"\n",
    "    logits_softmax = torch.softmax(logits, dim = -1)        # (batch, max_len, num_classes)\n",
    "    # print(logits_softmax)\n",
    "    _, y_pred_tags = torch.max(logits_softmax, dim = -1)    # (batch, max_len)\n",
    "    # print(y_pred_tags)\n",
    "    correct_pred = (y_pred_tags == target).float()          # (batch, max_len)\n",
    "    correct_pred = correct_pred * mask.float()              # (batch, max_len)\n",
    "    acc = correct_pred.sum() / torch.sum(mask)          \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1000, 0.2000, 0.9000],\n",
      "         [0.1000, 0.2000, 0.9000],\n",
      "         [0.1000, 0.2000, 0.9000]],\n",
      "\n",
      "        [[0.1000, 0.2000, 0.9000],\n",
      "         [0.1000, 0.2000, 0.9000],\n",
      "         [0.1000, 0.2000, 0.9000]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "logits = [[[0.1, 0.2, 0.9], [0.1, 0.2, 0.9],[0.1, 0.2, 0.9]],[[0.1, 0.2, 0.9], [0.1, 0.2, 0.9],[0.1, 0.2, 0.9]]]\n",
    "logits = torch.tensor(logits)\n",
    "print(logits)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 2],\n",
      "        [2, 0, 2]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# pred = [[2,2,2],[2,2,2]]\n",
    "\n",
    "target = [[2,0,2],[2,0,2]]\n",
    "target = torch.tensor(target)\n",
    "print(target)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "mask = [[1,1,0],[0,0,0]]\n",
    "mask = torch.tensor(mask)\n",
    "print(mask)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_acc(logits, target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0657)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def masked_ce_loss(logits, target, mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: (batch, max_len, num_classes),  not yet passed to Softmax \n",
    "        target: (batch, max_len) \n",
    "        mask:   (batch_size, max_len)\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "\n",
    "    logits_softmax = torch.softmax(logits, dim = -1)        # (batch, max_len, num_classes)\n",
    "    logits_log_softmax = torch.log(logits_softmax)          # (batch, max_len, num_classes)\n",
    "    target = torch.nn.functional.one_hot(target)            # (batch, max_len, num_classes)\n",
    "    multi = -torch.multiply(logits_log_softmax, target)     # (batch, max_len, num_classes)\n",
    "    sum_multi = multi.sum(-1)                               # (batch, max_len)\n",
    "    sum_multi_masked = sum_multi * mask                     # (batch, max_len)\n",
    "    sum_mask = mask.sum()                                   # (1,)\n",
    "    sum_multi_masked = sum_multi_masked.sum()               # (1,)\n",
    "    \n",
    "    return sum_multi_masked/(sum_mask + 1e-9)\n",
    "    \n",
    "masked_ce_loss(logits, target, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "def checkIfProcessRunning(processName):\n",
    "    '''\n",
    "    Check if there is any running process that contains the given name processName.\n",
    "    '''\n",
    "    #Iterate over the all the running process\n",
    "    for proc in psutil.process_iter():\n",
    "        try:\n",
    "            for cmd in proc.cmdline():\n",
    "            # Check if process name contains the given name string.\n",
    "                if processName in cmd:\n",
    "                    return True\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "            pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkIfProcessRunning('ccccc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8063a049ce6126424592ab63ae068ec0717401a263e6cd39dbb78c77b7761238"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('transformers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
