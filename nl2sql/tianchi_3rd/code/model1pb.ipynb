{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from keras_bert import load_vocabulary, load_trained_model_from_checkpoint, Tokenizer, get_checkpoint_paths\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Multiply, Masking, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from nl2sql.utils import read_data, read_tables, SQL, MultiSentenceTokenizer, Query, Question, Table\n",
    "from nl2sql.utils.optimizer import RAdam\n",
    "\n",
    "\n",
    "# config\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' \n",
    "NUM_GPUS = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fengyuan/anaconda3/envs/nl2sql/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
     ]
    }
   ],
   "source": [
    "## model1\n",
    "\n",
    "def get_model(num_sel_agg,num_cond_op,num_cond_conn_op):\n",
    "\n",
    "    bert_model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, seq_len=None)\n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = True\n",
    "        \n",
    "    inp_token_ids = Input(shape=(None,), name='input_token_ids', dtype='int32')\n",
    "    inp_segment_ids = Input(shape=(None,), name='input_segment_ids', dtype='int32')\n",
    "    inp_header_ids = Input(shape=(None,), name='input_header_ids', dtype='int32')\n",
    "    inp_header_mask = Input(shape=(None, ), name='input_header_mask')\n",
    "\n",
    "    x = bert_model([inp_token_ids, inp_segment_ids]) # (None, seq_len, 768)\n",
    "\n",
    "    # predict cond_conn_op\n",
    "    x_for_cond_conn_op = Lambda(lambda x: x[:, 0])(x) # (None, 768)\n",
    "    p_cond_conn_op = Dense(num_cond_conn_op, activation='softmax', name='output_cond_conn_op')(x_for_cond_conn_op)\n",
    "\n",
    "    # predict sel_agg\n",
    "    x_for_header = Lambda(seq_gather, name='header_seq_gather')([x, inp_header_ids]) # (None, h_len, 768)\n",
    "    header_mask = Lambda(lambda x: K.expand_dims(x, axis=-1))(inp_header_mask) # (None, h_len, 1)\n",
    "\n",
    "    x_for_header = Multiply()([x_for_header, header_mask])\n",
    "    x_for_header = Masking()(x_for_header)\n",
    "\n",
    "    p_sel_agg = Dense(num_sel_agg, activation='softmax', name='output_sel_agg')(x_for_header)\n",
    "\n",
    "    x_for_cond_op = Concatenate(axis=-1)([x_for_header, p_sel_agg])\n",
    "    p_cond_op = Dense(num_cond_op, activation='softmax', name='output_cond_op')(x_for_cond_op)\n",
    "\n",
    "\n",
    "    model = Model(\n",
    "        [inp_token_ids, inp_segment_ids, inp_header_ids, inp_header_mask],\n",
    "        [p_cond_conn_op, p_sel_agg, p_cond_op]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def seq_gather(x):\n",
    "    seq, idxs = x\n",
    "    idxs = K.cast(idxs, 'int32')\n",
    "    return K.tf.batch_gather(seq, idxs)\n",
    "\n",
    "bert_model_path = '../../../experiments/model/chinese_wwm_L-12_H-768_A-12'\n",
    "paths = get_checkpoint_paths(bert_model_path)\n",
    "\n",
    "model_path = '../model/m1_ep10.h5'\n",
    "\n",
    "# init model\n",
    "num_sel_agg = len(SQL.agg_sql_dict) + 1\n",
    "num_cond_op = len(SQL.op_sql_dict) + 1\n",
    "num_cond_conn_op = len(SQL.conn_sql_dict)\n",
    "\n",
    "model = get_model(num_sel_agg,num_cond_op,num_cond_conn_op)\n",
    "\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_header_ids:0': <tf.Tensor 'input_header_ids:0' shape=(?, ?) dtype=int32>,\n",
       " 'input_header_mask:0': <tf.Tensor 'input_header_mask:0' shape=(?, ?) dtype=float32>,\n",
       " 'input_segment_ids:0': <tf.Tensor 'input_segment_ids:0' shape=(?, ?) dtype=int32>,\n",
       " 'input_token_ids:0': <tf.Tensor 'input_token_ids:0' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.input[2].name\n",
    "\n",
    "input_dict = dict()\n",
    "\n",
    "for input_ in model.input:\n",
    "    input_dict[input_.name]=input_\n",
    "\n",
    "input_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_cond_conn_op/Softmax:0': <tf.Tensor 'output_cond_conn_op/Softmax:0' shape=(?, 3) dtype=float32>,\n",
       " 'output_cond_op/truediv:0': <tf.Tensor 'output_cond_op/truediv:0' shape=(?, ?, 5) dtype=float32>,\n",
       " 'output_sel_agg/truediv:0': <tf.Tensor 'output_sel_agg/truediv:0' shape=(?, ?, 7) dtype=float32>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = dict()\n",
    "\n",
    "for output_ in model.output:\n",
    "    output_dict[output_.name]=output_\n",
    "\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../model/m1_ep10/0/saved_model.pb\n",
      "save model pb success ...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "def export_savedmodel(model,output_path):\n",
    "    '''\n",
    "    传入keras model会自动保存为pb格式\n",
    "    '''\n",
    "    model_path = output_path # 模型保存的路径\n",
    "    model_version = 0 # 模型保存的版本\n",
    "    \n",
    "    # 从网络的输入输出创建预测的签名\n",
    "    input_dict = dict()\n",
    "    for input_ in model.input:\n",
    "        input_dict[input_.name]=input_\n",
    "\n",
    "    output_dict = dict()\n",
    "    for output_ in model.output:\n",
    "        output_dict[output_.name]=output_\n",
    "    \n",
    "    model_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "        inputs=input_dict, outputs=output_dict\n",
    "    )\n",
    "    # 使用utf-8编码将 字节或Unicode 转换为字节\n",
    "    export_path = os.path.join(compat.as_bytes(model_path), compat.as_bytes(str(model_version))) # 将保存路径和版本号join\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path) # 生成\"savedmodel\"协议缓冲区并保存变量和模型\n",
    "    builder.add_meta_graph_and_variables( # 将当前元图添加到savedmodel并保存变量\n",
    "    sess=K.get_session(), # 返回一个 session 默认返回tf的sess,否则返回keras的sess,两者都没有将创建一个全新的sess返回\n",
    "    tags=[tf.saved_model.tag_constants.SERVING], # 导出模型tag为SERVING(其他可选TRAINING,EVAL,GPU,TPU)\n",
    "    clear_devices=True, # 清除设备信息\n",
    "    signature_def_map={ # 签名定义映射\n",
    "        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: # 默认服务签名定义密钥\n",
    "        model_signature # 网络的输入输出策创建预测的签名\n",
    "    })\n",
    "    builder.save() # 将\"savedmodel\"协议缓冲区写入磁盘.\n",
    "    print(\"save model pb success ...\")\n",
    "\n",
    "output_path = '../model/m1_ep10'\n",
    "export_savedmodel(model, output_path) # 将模型传入保存模型的方法内,模型保存成功."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8063a049ce6126424592ab63ae068ec0717401a263e6cd39dbb78c77b7761238"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('transformers': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
