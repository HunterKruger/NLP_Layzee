{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer模型\n",
    "Transformer的整体结构是由点乘自注意力、全连接层堆叠而成的编码器和解码器。\n",
    "![Transformer](./image/transformer_001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding填充mask\n",
    "def padding_mask(seq):\n",
    "    mask = tf.math.not_equal(seq, 0)\n",
    "    return mask\n",
    "\n",
    "# decode mask\n",
    "def look_ahead_mask(size):\n",
    "    ahead_mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    ahead_mask = tf.cast(ahead_mask, dtype=tf.bool)\n",
    "    return ahead_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 位置编码信息\n",
    "transformer模型不同与RNN模型，RNN天然就有位置信息，transformer中通过额外输入每个时刻的位置信息。通过sin和cos函数交替生成位置编码信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码信息\n",
    "def positional_embedding(maxlen, model_size):\n",
    "    PE = np.zeros((maxlen, model_size))\n",
    "    for i in range(maxlen):\n",
    "        for j in range(model_size):\n",
    "            if j % 2 == 0:\n",
    "                PE[i, j] = np.sin(i / 10000 ** (j / model_size))\n",
    "            else:\n",
    "                PE[i, j] = np.cos(i / 10000 ** ((j-1) / model_size))\n",
    "    PE = tf.constant(PE, dtype=tf.float32)\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Attention\n",
    "注意力函数可以看成是将一个输出向量映射成一个查询向量query和一组键key-值value向量对。输出向量为这些值向量的加权求和，其中每个值向量的权重由查询向量和值对应的键向量计算得出。\n",
    "\n",
    "我们称其为“量化点乘注意力”， 输入包括d_k维的查询向量和键向量以及d_v维的值向量，最后使用softmax函数获得这些值对应的权重。\n",
    "\n",
    "![Transformer](./image/transformer_002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Head Attention\n",
    "多头注意力使模型联合感知不同位置的不同特征表征。单个头的注意力会抑制这些表征。\n",
    "![Transformer](./image/transformer_003.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class MultiHeadAttention(keras.Model):\n",
    "    def __init__(self, model_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = model_size // num_heads\n",
    "        self.WQ = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.WK = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.WV = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.WO = keras.layers.Dense(model_size)\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "        # query shape: (batch, query_len, model_size)\n",
    "        # key shape: (batch, key_len, model_size)\n",
    "        # value shape: (batch, value_len, model_size)\n",
    "        context_heads = []\n",
    "        for i in range(self.num_heads):\n",
    "            q = self.WQ[i](query)\n",
    "            k = self.WK[i](key)\n",
    "            v = self.WV[i](value)\n",
    "            matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "            dk = tf.dtypes.cast(self.head_size, tf.float32)\n",
    "            # 缩放 matmul_qk\n",
    "            score = matmul_qk / tf.math.sqrt(dk)\n",
    "            if mask is not None:\n",
    "                score += (1 - mask) * -1e9\n",
    "            alpha = tf.nn.softmax(score, axis=-1)\n",
    "            context = tf.matmul(alpha, v)\n",
    "            \n",
    "            context_heads.append(context)\n",
    "            \n",
    "        concat_attention = tf.concat(context_heads, axis=2)\n",
    "        output = self.WO(concat_attention)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里也可以中tensorflow中keras封装好的Attention层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.Model):\n",
    "    def __init__(self, model_size, num_heads, causal=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = model_size // num_heads\n",
    "        self.WQ = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.WK = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.WV = [keras.layers.Dense(self.head_size) for _ in range(num_heads)]\n",
    "        self.Attention = keras.layers.Attention(use_scale=True, causal=causal)\n",
    "        self.WO = keras.layers.Dense(model_size)\n",
    "    \n",
    "    def call(self, query, key, value, mask):\n",
    "        # query shape: (batch, query_len, model_size)\n",
    "        # key shape: (batch, key_len, model_size)\n",
    "        # value shape: (batch, value_len, model_size)\n",
    "        context_heads = []\n",
    "        for i in range(self.num_heads):\n",
    "            q = self.WQ[i](query)\n",
    "            k = self.WK[i](key)\n",
    "            v = self.WV[i](value)\n",
    "            context = self.Attention([q, k, v], [mask, mask])\n",
    "            context_heads.append(context)\n",
    "            \n",
    "        concat_attention = tf.concat(context_heads, axis=2)\n",
    "        output = self.WO(concat_attention)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point wise feed forward network\n",
    "class FeedForwardNetwork(keras.Model):\n",
    "    def __init__(self, dff_size, model_size):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(dff_size, activation=\"relu\")\n",
    "        self.dense2 = keras.layers.Dense(model_size)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer层\n",
    "class EncoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, model_size, num_heads, dff_size, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(model_size, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(dff_size, model_size)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        # multi head attention\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        # residual connection\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        # ffn layer\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        # Residual connection\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层Encoder\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, model_size)\n",
    "        self.pos_embedding = positional_embedding(maxlen, model_size)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(model_size,num_heads,dff_size,rate) for _ in range(num_layers)]\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # input embedding\n",
    "        x = self.embedding(x)\n",
    "        # positional embedding\n",
    "        x += self.pos_embedding\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, training, padding_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, model_size, num_heads, dff_size, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mask_attention = MultiHeadAttention(model_size, num_heads, causal=True)\n",
    "        self.attention = MultiHeadAttention(model_size, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(dff_size, model_size)\n",
    "        \n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, x, enc_output, training, padding_mask):\n",
    "        attn_decoder = self.mask_attention(x, x, x, padding_mask)\n",
    "        out1 = self.layernorm1(x + attn_decoder)\n",
    "        \n",
    "        attn_encoder_decoder = self.attention(out1, enc_output, enc_output, padding_mask)\n",
    "        out2 = self.layernorm2(out1 + attn_encoder_decoder)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)\n",
    "        \n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层Decoder\n",
    "class Decoder(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, model_size)\n",
    "        self.pos_embedding = positional_embedding(maxlen, model_size)\n",
    "        \n",
    "        self.decoder_layers = [DecoderLayer(model_size,num_heads,dff_size,rate) for _ in range(num_layers)]\n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, enc_output, x, training, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # input embedding\n",
    "        x = self.embedding(x)\n",
    "        # positional embedding\n",
    "        x += self.pos_embedding\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.decoder_layers[i](x, enc_output, training, padding_mask)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder和Decoder组合成Transformer，继承keras.Model实现\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, model_size, num_heads, dff_size, vocab_size, maxlen, rete=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "        self.decoder = Decoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "        self.final_dense = keras.layers.Dense(vocab_size, name=\"final_output\")\n",
    "        \n",
    "    def call(self, inputs, targets, training, enc_padding_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inputs, training, enc_padding_mask)\n",
    "        dec_output = self.decoder(enc_output, targets, training, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_dense(dec_output)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder和Decoder组合成Transformer\n",
    "def transformer(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen):\n",
    "    enc_inputs = keras.Input(shape=(maxlen,), name=\"enc_input\")\n",
    "    dec_inputs = keras.Input(shape=(maxlen,), name=\"dec_input\")\n",
    "    dec_outputs = keras.Input(shape=(maxlen,), name=\"dec_output\")\n",
    "\n",
    "    encoder = Encoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "    decoder = Decoder(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "    final_dense = Keras.layers.Dense(vocab_size, name=\"final_output\")\n",
    "\n",
    "    enc_output = encoder(enc_inputs, True, None)\n",
    "    dec_output = decoder(enc_output, dec_inputs, True, None)\n",
    "\n",
    "    final_output = final_dense(dec_output)\n",
    "\n",
    "    model = keras.models.Model(inputs=[enc_inputs, dec_inputs], outputs=final_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Encoder)               (None, 10, 128)      392962      enc_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Decoder)               (None, 10, 128)      525572      encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 10, 1000)     129000      decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,047,534\n",
      "Trainable params: 1,047,534\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "num_layers=2 \n",
    "model_size=128\n",
    "num_heads=4\n",
    "dff_size=256\n",
    "vocab_size=1000\n",
    "maxlen = 10\n",
    "\n",
    "model = transformer(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 128)           128000    \n",
      "_________________________________________________________________\n",
      "encoder_layer (EncoderLayer) multiple                  132481    \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (EncoderLaye multiple                  132481    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 392,962\n",
      "Trainable params: 392,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Tensor(\"enc_input:0\", shape=(None, 10), dtype=float32)\n",
      "Tensor(\"encoder/Identity:0\", shape=(None, 10, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder = model.get_layer(\"encoder\")\n",
    "print(encoder.summary())\n",
    "print(encoder.input)\n",
    "print(encoder.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (InputLayer)          [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer (Transformer)       (None, 10, 1000)     1047534     enc_input[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,047,534\n",
      "Trainable params: 1,047,534\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "maxlen = 10\n",
    "num_layers=2\n",
    "model_size=128\n",
    "num_heads=4\n",
    "dff_size=256\n",
    "vocab_size=1000\n",
    "\n",
    "enc_inputs = Input(shape=(maxlen,), name=\"enc_input\")\n",
    "dec_inputs = Input(shape=(maxlen,), name=\"dec_input\")\n",
    "dec_outputs = Input(shape=(maxlen,), name=\"dec_output\")\n",
    "\n",
    "transformer = Transformer(num_layers, model_size, num_heads, dff_size, vocab_size, maxlen)\n",
    "\n",
    "outputs = transformer(enc_inputs, dec_inputs, training=True, enc_padding_mask=None, dec_padding_mask=None)\n",
    "\n",
    "model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            (None, 10, 128)           392962    \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            (None, 10, 128)           525572    \n",
      "_________________________________________________________________\n",
      "final_output (Dense)         (None, 10, 1000)          129000    \n",
      "=================================================================\n",
      "Total params: 1,047,534\n",
      "Trainable params: 1,047,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sub_model_transformer = model.get_layer(\"transformer\")\n",
    "sub_model_transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 128)           128000    \n",
      "_________________________________________________________________\n",
      "encoder_layer (EncoderLayer) multiple                  132481    \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (EncoderLaye multiple                  132481    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 392,962\n",
      "Trainable params: 392,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = sub_model_transformer.get_layer(\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 128)           128000    \n",
      "_________________________________________________________________\n",
      "decoder_layer (DecoderLayer) multiple                  198786    \n",
      "_________________________________________________________________\n",
      "decoder_layer_1 (DecoderLaye multiple                  198786    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 525,572\n",
      "Trainable params: 525,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = sub_model_transformer.get_layer(\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
