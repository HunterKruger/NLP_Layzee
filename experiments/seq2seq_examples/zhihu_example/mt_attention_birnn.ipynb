{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简介\n",
    "\n",
    "该代码基于English-French parallel corpus实现了机器翻译模型，模型在基础的Seq2Seq模型上加入Attention机制与BiRNN。代码采用Keras框架实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - 加载包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, Reshape\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'# specify GPU usage  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - 加载源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English source data\n",
    "with open(\"small_vocab_en\", \"r\", encoding=\"utf-8\") as f:\n",
    "    source_text = f.read()\n",
    "\n",
    "# French target data\n",
    "with open(\"small_vocab_fr\", \"r\", encoding=\"utf-8\") as f:\n",
    "    target_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - 数据统计\n",
    "\n",
    "对语料数据进行统计性分析：\n",
    "- 对英文语料：统计句子数、平均句子长度以及最大句子长度\n",
    "- 对法语语料：统计句子数、平均句子长度以及最大句子长度\n",
    "- 打印语料数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 227\n",
      "-----English Text-----\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 13.225277634719028\n",
      "Max number of words in a sentence: 17\n",
      "\n",
      "-----French Text-----\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 14.226612312401622\n",
      "Max number of words in a sentence: 23\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "# Separate the source language text by spaces, to see how many distinct words are contained in it\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "# 统计英文语料数据\n",
    "print(\"-\"*5 + \"English Text\" + \"-\"*5)\n",
    "sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "print('Max number of words in a sentence: {}'.format(np.max(word_counts)))\n",
    "\n",
    "# 统计法语语料数据\n",
    "print()\n",
    "print(\"-\"*5 + \"French Text\" + \"-\"*5)\n",
    "sentences = target_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "print('Max number of words in a sentence: {}'.format(np.max(word_counts)))\n",
    "\n",
    "# 打印语料的前10个句子\n",
    "print()\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))\n",
    "print()\n",
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - 数据预处理\n",
    "\n",
    "数据预处理部分主要包括：\n",
    "- 构造英文与法语的词典\n",
    "- 构造语料单词到编码的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造英文词典\n",
    "source_vocab = list(set(source_text.lower().split()))\n",
    "# 构造法语词典\n",
    "target_vocab = list(set(target_text.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of English vocab is : 227\n",
      "The size of French vocab is : 354\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of English vocab is : {}\".format(len(source_vocab)))\n",
    "print(\"The size of French vocab is : {}\".format(len(target_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加特殊编码\n",
    "SOURCE_CODES = ['<PAD>', '<UNK>']\n",
    "TARGET_CODES = ['<PAD>', '<EOS>', '<UNK>', '<GO>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造英文语料的映射表\n",
    "source_vocab_to_int = {word: idx for idx, word in enumerate(SOURCE_CODES + source_vocab)}\n",
    "source_int_to_vocab = {idx: word for idx, word in enumerate(SOURCE_CODES + source_vocab)}\n",
    "\n",
    "# 构造法语语料的映射表\n",
    "target_vocab_to_int = {word: idx for idx, word in enumerate(TARGET_CODES + target_vocab)}\n",
    "target_int_to_vocab = {idx: word for idx, word in enumerate(TARGET_CODES + target_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of English Map is : 229\n",
      "The size of French Map is : 358\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of English Map is : {}\".format(len(source_vocab_to_int)))\n",
    "print(\"The size of French Map is : {}\".format(len(target_vocab_to_int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - 语料转换\n",
    "\n",
    "在构造完英文与法语映射表的基础上，我们此时将原始文本语料转化为数字编码。\n",
    "\n",
    "例如， 对句子 ”I love machine learning and deep learning\" ，我们可以编码为 [28, 29, 274, 873, 12, 983, 873, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] （其中0代表< PAD >)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_int(sentence, map_dict, max_length=20, is_target=False):\n",
    "    \"\"\"\n",
    "    Encoding the text into integers.\n",
    "    \n",
    "    @param sentence: 完整的句子，str类型\n",
    "    @param map_dict: 单词到数字编码的映射\n",
    "    @param max_length: 最大句子长度\n",
    "    @param is_target: 当前传入的句子是否是目标语句。\n",
    "                      对于目标语句，我们要在末尾添加\"<EOS>\"\n",
    "    \"\"\"\n",
    "    \n",
    "    text_to_idx = []\n",
    "    # 特殊单词的数字编码\n",
    "    unk_idx = map_dict.get(\"<UNK>\")\n",
    "    pad_idx = map_dict.get(\"<PAD>\")\n",
    "    eos_idx = map_dict.get(\"<EOS>\")\n",
    "    \n",
    "    # 如果不是目标语句（即源语句）\n",
    "    if not is_target:\n",
    "        for word in sentence.split():\n",
    "            text_to_idx.append(map_dict.get(word, unk_idx))\n",
    "    \n",
    "    # 目标语句要对结尾添加\"<EOS>\"\n",
    "    else:\n",
    "        for word in sentence.split():\n",
    "            text_to_idx.append(map_dict.get(word, unk_idx))\n",
    "        text_to_idx.append(eos_idx)\n",
    "    \n",
    "    # 超长句子进行截断\n",
    "    if len(text_to_idx) > max_length:\n",
    "        return text_to_idx[:max_length]\n",
    "    # 不足长度的句子进行\"<PAD>\"\n",
    "    else:\n",
    "        text_to_idx = text_to_idx + [pad_idx] * (max_length - len(text_to_idx))\n",
    "        return text_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137861/137861 [00:01<00:00, 120345.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对英文语料进行编码，其中设置英文句子最大长度为20\n",
    "Tx = 20\n",
    "source_text_to_int = []\n",
    "\n",
    "for sentence in tqdm.tqdm(source_text.split(\"\\n\")):\n",
    "    source_text_to_int.append(text_to_int(sentence, source_vocab_to_int, Tx, is_target=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137861/137861 [00:01<00:00, 117676.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对法语语料进行编码，其中设置法语句子最大长度为25\n",
    "Ty = 25\n",
    "target_text_to_int = []\n",
    "\n",
    "for sentence in tqdm.tqdm(target_text.split(\"\\n\")):\n",
    "    target_text_to_int.append(text_to_int(sentence, target_vocab_to_int, Ty, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----English example-----\n",
      "the united states is never beautiful during march , and it is usually relaxing in summer .\n",
      "[194, 88, 34, 117, 168, 64, 179, 199, 140, 222, 107, 117, 106, 219, 82, 210, 108, 0, 0, 0]\n",
      "\n",
      "-----French example-----\n",
      "les états-unis est jamais belle en mars , et il est relaxant habituellement en été .\n",
      "[161, 136, 249, 333, 31, 299, 210, 321, 102, 52, 249, 98, 295, 299, 109, 54, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "random_index = 77\n",
    "\n",
    "print(\"-\"*5 + \"English example\" + \"-\"*5)\n",
    "print(source_text.split(\"\\n\")[random_index])\n",
    "print(source_text_to_int[random_index])\n",
    "\n",
    "print()\n",
    "print(\"-\"*5 + \"French example\" + \"-\"*5)\n",
    "print(target_text.split(\"\\n\")[random_index])\n",
    "print(target_text_to_int[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After encoding the source and target text into numbers, we need to do one-hot-encoding of them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(source_text_to_int)\n",
    "Y = np.array(target_text_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对X和Y做One Hot Encoding\n",
    "Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(source_vocab_to_int)), X)))\n",
    "Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab_to_int)), Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义softmax函数\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"\n",
    "    Softmax activation function.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局网络层对象\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_tanh = Dense(32, activation = \"tanh\")\n",
    "densor_relu = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Attention机制的实现，返回加权后的Context Vector\n",
    "    \n",
    "    @param a: BiRNN的隐层状态\n",
    "    @param s_prev: Decoder端LSTM的上一轮隐层输出\n",
    "    \n",
    "    Returns:\n",
    "    context: 加权后的Context Vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将s_prev复制Tx次\n",
    "    s_prev = repeator(s_prev)\n",
    "    # 拼接BiRNN隐层状态与s_prev\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # 计算energies\n",
    "    e = densor_tanh(concat)\n",
    "    energies = densor_relu(e)\n",
    "    # 计算weights\n",
    "    alphas = activator(energies)\n",
    "    # 加权得到Context Vector\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - 模型\n",
    "\n",
    "主要包括：\n",
    "\n",
    "- Embedding层\n",
    "- Seq2Seq模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 - 构造Embedding层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练好的glove词向量\n",
    "with open(\"glove.6B.100d.txt\", 'r') as f:\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        curr_word = line[0]\n",
    "        words.add(curr_word)\n",
    "        word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, source_vocab_to_int):\n",
    "    \"\"\"\n",
    "    构造Embedding层并加载预训练好的词向量（这里我使用的是100维）\n",
    "\n",
    "    @param word_to_vec_map: 单词到向量的映射\n",
    "    @param word_to_index: 单词到数字编码的映射\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(source_vocab_to_int) + 1        # Keras Embedding的API要求+1\n",
    "    emb_dim = word_to_vec_map[\"the\"].shape[0]\n",
    "    \n",
    "    # 初始化embedding矩阵\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # 用词向量填充embedding矩阵\n",
    "    for word, index in source_vocab_to_int.items():\n",
    "        word_vector = word_to_vec_map.get(word, np.zeros(emb_dim))\n",
    "        emb_matrix[index, :] = word_vector\n",
    "\n",
    "    # 定义Embedding层，并指定不需要训练该层的权重\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "\n",
    "    # build\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # set weights\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取Embedding layer\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, source_vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 - 定义超参数与模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 # The hidden size of Bi-LSTM\n",
    "n_s = 128 # The hidden size of LSTM in Decoder\n",
    "decoder_LSTM_cell = LSTM(n_s, return_state=True)\n",
    "output_layer = Dense(len(target_vocab_to_int), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络层对象（用在model函数中）\n",
    "reshapor = Reshape((1, len(target_vocab_to_int)))\n",
    "concator = Concatenate(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, source_vocab_size, target_vocab_size):\n",
    "    \"\"\"\n",
    "    构造模型\n",
    "    \n",
    "    @param Tx: 输入序列的长度\n",
    "    @param Ty: 输出序列的长度\n",
    "    @param n_a: Encoder端Bi-LSTM隐层结点数\n",
    "    @param n_s: Decoder端LSTM隐层结点数\n",
    "    @param source_vocab_size: 输入（英文）语料的词典大小\n",
    "    @param target_vocab_size: 输出（法语）语料的词典大小\n",
    "    \"\"\"\n",
    "    \n",
    "    # 定义输入层\n",
    "    X = Input(shape=(Tx,))\n",
    "    # Embedding层\n",
    "    embed = embedding_layer(X)\n",
    "    # Decoder端LSTM的初始状态\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    \n",
    "    # Decoder端LSTM的初始输入\n",
    "    out0 = Input(shape=(target_vocab_size, ), name='out0')\n",
    "    out = reshapor(out0)\n",
    "    \n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # 模型输出列表，用来存储翻译的结果\n",
    "    outputs = []\n",
    "    \n",
    "    # 定义Bi-LSTM\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(embed)\n",
    "    \n",
    "    # Decoder端，迭代Ty轮，每轮生成一个翻译结果\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # 获取Context Vector\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # 将Context Vector与上一轮的翻译结果进行concat\n",
    "        context = concator([context, reshapor(out)])\n",
    "        s, _, c = decoder_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # 将LSTM的输出结果与全连接层链接\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # 存储输出结果\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model([X, s0, c0, out0], outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(source_vocab_to_int), len(target_vocab_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 100)      23000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 20, 64)       34048       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 20, 128)      0           s0[0][0]                         \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[7][0]                       \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[9][0]                       \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[18][0]                      \n",
      "                                                                 lstm[19][0]                      \n",
      "                                                                 lstm[20][0]                      \n",
      "                                                                 lstm[21][0]                      \n",
      "                                                                 lstm[22][0]                      \n",
      "                                                                 lstm[23][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20, 192)      0           bidirectional[0][0]              \n",
      "                                                                 repeat_vector[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[1][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[2][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[3][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[4][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[5][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[6][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[7][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[8][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[9][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[10][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[11][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[12][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[13][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[14][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[15][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[16][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[17][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[18][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[19][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[20][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[21][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[22][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[23][0]             \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[24][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20, 32)       6176        concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 concatenate[2][0]                \n",
      "                                                                 concatenate[3][0]                \n",
      "                                                                 concatenate[4][0]                \n",
      "                                                                 concatenate[5][0]                \n",
      "                                                                 concatenate[6][0]                \n",
      "                                                                 concatenate[7][0]                \n",
      "                                                                 concatenate[8][0]                \n",
      "                                                                 concatenate[9][0]                \n",
      "                                                                 concatenate[10][0]               \n",
      "                                                                 concatenate[11][0]               \n",
      "                                                                 concatenate[12][0]               \n",
      "                                                                 concatenate[13][0]               \n",
      "                                                                 concatenate[14][0]               \n",
      "                                                                 concatenate[15][0]               \n",
      "                                                                 concatenate[16][0]               \n",
      "                                                                 concatenate[17][0]               \n",
      "                                                                 concatenate[18][0]               \n",
      "                                                                 concatenate[19][0]               \n",
      "                                                                 concatenate[20][0]               \n",
      "                                                                 concatenate[21][0]               \n",
      "                                                                 concatenate[22][0]               \n",
      "                                                                 concatenate[23][0]               \n",
      "                                                                 concatenate[24][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 1)        33          dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense[2][0]                      \n",
      "                                                                 dense[3][0]                      \n",
      "                                                                 dense[4][0]                      \n",
      "                                                                 dense[5][0]                      \n",
      "                                                                 dense[6][0]                      \n",
      "                                                                 dense[7][0]                      \n",
      "                                                                 dense[8][0]                      \n",
      "                                                                 dense[9][0]                      \n",
      "                                                                 dense[10][0]                     \n",
      "                                                                 dense[11][0]                     \n",
      "                                                                 dense[12][0]                     \n",
      "                                                                 dense[13][0]                     \n",
      "                                                                 dense[14][0]                     \n",
      "                                                                 dense[15][0]                     \n",
      "                                                                 dense[16][0]                     \n",
      "                                                                 dense[17][0]                     \n",
      "                                                                 dense[18][0]                     \n",
      "                                                                 dense[19][0]                     \n",
      "                                                                 dense[20][0]                     \n",
      "                                                                 dense[21][0]                     \n",
      "                                                                 dense[22][0]                     \n",
      "                                                                 dense[23][0]                     \n",
      "                                                                 dense[24][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out0 (InputLayer)               [(None, 358)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "                                                                 dense_1[20][0]                   \n",
      "                                                                 dense_1[21][0]                   \n",
      "                                                                 dense_1[22][0]                   \n",
      "                                                                 dense_1[23][0]                   \n",
      "                                                                 dense_1[24][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 358)       0           out0[0][0]                       \n",
      "                                                                 reshape[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "                                                                 dense_2[10][0]                   \n",
      "                                                                 dense_2[11][0]                   \n",
      "                                                                 dense_2[12][0]                   \n",
      "                                                                 dense_2[13][0]                   \n",
      "                                                                 dense_2[14][0]                   \n",
      "                                                                 dense_2[15][0]                   \n",
      "                                                                 dense_2[16][0]                   \n",
      "                                                                 dense_2[17][0]                   \n",
      "                                                                 dense_2[18][0]                   \n",
      "                                                                 dense_2[19][0]                   \n",
      "                                                                 dense_2[20][0]                   \n",
      "                                                                 dense_2[21][0]                   \n",
      "                                                                 dense_2[22][0]                   \n",
      "                                                                 dense_2[23][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[20][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[21][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[22][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[23][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 attention_weights[24][0]         \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 422)       0           dot[0][0]                        \n",
      "                                                                 reshape[1][0]                    \n",
      "                                                                 dot[1][0]                        \n",
      "                                                                 reshape[2][0]                    \n",
      "                                                                 dot[2][0]                        \n",
      "                                                                 reshape[3][0]                    \n",
      "                                                                 dot[3][0]                        \n",
      "                                                                 reshape[4][0]                    \n",
      "                                                                 dot[4][0]                        \n",
      "                                                                 reshape[5][0]                    \n",
      "                                                                 dot[5][0]                        \n",
      "                                                                 reshape[6][0]                    \n",
      "                                                                 dot[6][0]                        \n",
      "                                                                 reshape[7][0]                    \n",
      "                                                                 dot[7][0]                        \n",
      "                                                                 reshape[8][0]                    \n",
      "                                                                 dot[8][0]                        \n",
      "                                                                 reshape[9][0]                    \n",
      "                                                                 dot[9][0]                        \n",
      "                                                                 reshape[10][0]                   \n",
      "                                                                 dot[10][0]                       \n",
      "                                                                 reshape[11][0]                   \n",
      "                                                                 dot[11][0]                       \n",
      "                                                                 reshape[12][0]                   \n",
      "                                                                 dot[12][0]                       \n",
      "                                                                 reshape[13][0]                   \n",
      "                                                                 dot[13][0]                       \n",
      "                                                                 reshape[14][0]                   \n",
      "                                                                 dot[14][0]                       \n",
      "                                                                 reshape[15][0]                   \n",
      "                                                                 dot[15][0]                       \n",
      "                                                                 reshape[16][0]                   \n",
      "                                                                 dot[16][0]                       \n",
      "                                                                 reshape[17][0]                   \n",
      "                                                                 dot[17][0]                       \n",
      "                                                                 reshape[18][0]                   \n",
      "                                                                 dot[18][0]                       \n",
      "                                                                 reshape[19][0]                   \n",
      "                                                                 dot[19][0]                       \n",
      "                                                                 reshape[20][0]                   \n",
      "                                                                 dot[20][0]                       \n",
      "                                                                 reshape[21][0]                   \n",
      "                                                                 dot[21][0]                       \n",
      "                                                                 reshape[22][0]                   \n",
      "                                                                 dot[22][0]                       \n",
      "                                                                 reshape[23][0]                   \n",
      "                                                                 dot[23][0]                       \n",
      "                                                                 reshape[24][0]                   \n",
      "                                                                 dot[24][0]                       \n",
      "                                                                 reshape[25][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 282112      concatenate_1[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[1][2]                       \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[2][2]                       \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[3][2]                       \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[4][2]                       \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[5][2]                       \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[6][2]                       \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 lstm[7][0]                       \n",
      "                                                                 lstm[7][2]                       \n",
      "                                                                 concatenate_1[9][0]              \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[8][2]                       \n",
      "                                                                 concatenate_1[10][0]             \n",
      "                                                                 lstm[9][0]                       \n",
      "                                                                 lstm[9][2]                       \n",
      "                                                                 concatenate_1[11][0]             \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[10][2]                      \n",
      "                                                                 concatenate_1[12][0]             \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[11][2]                      \n",
      "                                                                 concatenate_1[13][0]             \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[12][2]                      \n",
      "                                                                 concatenate_1[14][0]             \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[13][2]                      \n",
      "                                                                 concatenate_1[15][0]             \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[14][2]                      \n",
      "                                                                 concatenate_1[16][0]             \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[15][2]                      \n",
      "                                                                 concatenate_1[17][0]             \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[16][2]                      \n",
      "                                                                 concatenate_1[18][0]             \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[17][2]                      \n",
      "                                                                 concatenate_1[19][0]             \n",
      "                                                                 lstm[18][0]                      \n",
      "                                                                 lstm[18][2]                      \n",
      "                                                                 concatenate_1[20][0]             \n",
      "                                                                 lstm[19][0]                      \n",
      "                                                                 lstm[19][2]                      \n",
      "                                                                 concatenate_1[21][0]             \n",
      "                                                                 lstm[20][0]                      \n",
      "                                                                 lstm[20][2]                      \n",
      "                                                                 concatenate_1[22][0]             \n",
      "                                                                 lstm[21][0]                      \n",
      "                                                                 lstm[21][2]                      \n",
      "                                                                 concatenate_1[23][0]             \n",
      "                                                                 lstm[22][0]                      \n",
      "                                                                 lstm[22][2]                      \n",
      "                                                                 concatenate_1[24][0]             \n",
      "                                                                 lstm[23][0]                      \n",
      "                                                                 lstm[23][2]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 358)          46182       lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "                                                                 lstm[6][0]                       \n",
      "                                                                 lstm[7][0]                       \n",
      "                                                                 lstm[8][0]                       \n",
      "                                                                 lstm[9][0]                       \n",
      "                                                                 lstm[10][0]                      \n",
      "                                                                 lstm[11][0]                      \n",
      "                                                                 lstm[12][0]                      \n",
      "                                                                 lstm[13][0]                      \n",
      "                                                                 lstm[14][0]                      \n",
      "                                                                 lstm[15][0]                      \n",
      "                                                                 lstm[16][0]                      \n",
      "                                                                 lstm[17][0]                      \n",
      "                                                                 lstm[18][0]                      \n",
      "                                                                 lstm[19][0]                      \n",
      "                                                                 lstm[20][0]                      \n",
      "                                                                 lstm[21][0]                      \n",
      "                                                                 lstm[22][0]                      \n",
      "                                                                 lstm[23][0]                      \n",
      "                                                                 lstm[24][0]                      \n",
      "==================================================================================================\n",
      "Total params: 391,551\n",
      "Trainable params: 368,551\n",
      "Non-trainable params: 23,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001),\n",
    "                    metrics=['accuracy'],\n",
    "                    loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"pretrained_seq2seq_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化各类向量\n",
    "m = X.shape[0]\n",
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "out0 = np.zeros((m, len(target_vocab_to_int)))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1078/1078 [==============================] - 320s 232ms/step - loss: 28.1056 - dense_2_loss: 0.9751 - dense_2_1_loss: 1.0814 - dense_2_2_loss: 1.1136 - dense_2_3_loss: 2.1944 - dense_2_4_loss: 2.0384 - dense_2_5_loss: 1.8404 - dense_2_6_loss: 2.0908 - dense_2_7_loss: 1.5040 - dense_2_8_loss: 1.3719 - dense_2_9_loss: 1.6248 - dense_2_10_loss: 1.7043 - dense_2_11_loss: 1.9585 - dense_2_12_loss: 1.9868 - dense_2_13_loss: 1.8179 - dense_2_14_loss: 1.6902 - dense_2_15_loss: 1.1962 - dense_2_16_loss: 0.8342 - dense_2_17_loss: 0.5174 - dense_2_18_loss: 0.2523 - dense_2_19_loss: 0.1079 - dense_2_20_loss: 0.0532 - dense_2_21_loss: 0.0405 - dense_2_22_loss: 0.0378 - dense_2_23_loss: 0.0370 - dense_2_24_loss: 0.0365 - dense_2_accuracy: 0.7239 - dense_2_1_accuracy: 0.7111 - dense_2_2_accuracy: 0.6970 - dense_2_3_accuracy: 0.3605 - dense_2_4_accuracy: 0.4542 - dense_2_5_accuracy: 0.4853 - dense_2_6_accuracy: 0.4186 - dense_2_7_accuracy: 0.5737 - dense_2_8_accuracy: 0.5749 - dense_2_9_accuracy: 0.5163 - dense_2_10_accuracy: 0.5310 - dense_2_11_accuracy: 0.4670 - dense_2_12_accuracy: 0.4952 - dense_2_13_accuracy: 0.5478 - dense_2_14_accuracy: 0.5695 - dense_2_15_accuracy: 0.6819 - dense_2_16_accuracy: 0.7501 - dense_2_17_accuracy: 0.8460 - dense_2_18_accuracy: 0.9374 - dense_2_19_accuracy: 0.9827 - dense_2_20_accuracy: 0.9966 - dense_2_21_accuracy: 0.9988 - dense_2_22_accuracy: 0.9990 - dense_2_23_accuracy: 0.9990 - dense_2_24_accuracy: 0.9991\n",
      "Epoch 2/5\n",
      "1078/1078 [==============================] - 176s 163ms/step - loss: 13.2865 - dense_2_loss: 0.1722 - dense_2_1_loss: 0.2545 - dense_2_2_loss: 0.3886 - dense_2_3_loss: 0.9224 - dense_2_4_loss: 0.9534 - dense_2_5_loss: 0.8574 - dense_2_6_loss: 1.1102 - dense_2_7_loss: 0.7027 - dense_2_8_loss: 0.6280 - dense_2_9_loss: 0.8515 - dense_2_10_loss: 0.8470 - dense_2_11_loss: 1.0089 - dense_2_12_loss: 1.1113 - dense_2_13_loss: 1.0087 - dense_2_14_loss: 0.9492 - dense_2_15_loss: 0.6439 - dense_2_16_loss: 0.4324 - dense_2_17_loss: 0.2660 - dense_2_18_loss: 0.1239 - dense_2_19_loss: 0.0423 - dense_2_20_loss: 0.0094 - dense_2_21_loss: 0.0017 - dense_2_22_loss: 3.9455e-04 - dense_2_23_loss: 2.9469e-04 - dense_2_24_loss: 1.4561e-04 - dense_2_accuracy: 0.9548 - dense_2_1_accuracy: 0.9307 - dense_2_2_accuracy: 0.8899 - dense_2_3_accuracy: 0.7294 - dense_2_4_accuracy: 0.7189 - dense_2_5_accuracy: 0.7197 - dense_2_6_accuracy: 0.6263 - dense_2_7_accuracy: 0.7736 - dense_2_8_accuracy: 0.8028 - dense_2_9_accuracy: 0.7207 - dense_2_10_accuracy: 0.7497 - dense_2_11_accuracy: 0.7061 - dense_2_12_accuracy: 0.6728 - dense_2_13_accuracy: 0.7024 - dense_2_14_accuracy: 0.7162 - dense_2_15_accuracy: 0.8141 - dense_2_16_accuracy: 0.8707 - dense_2_17_accuracy: 0.9164 - dense_2_18_accuracy: 0.9602 - dense_2_19_accuracy: 0.9868 - dense_2_20_accuracy: 0.9978 - dense_2_21_accuracy: 0.9998 - dense_2_22_accuracy: 1.0000 - dense_2_23_accuracy: 1.0000 - dense_2_24_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1078/1078 [==============================] - 213s 197ms/step - loss: 8.3924 - dense_2_loss: 0.1352 - dense_2_1_loss: 0.1783 - dense_2_2_loss: 0.2022 - dense_2_3_loss: 0.4139 - dense_2_4_loss: 0.5204 - dense_2_5_loss: 0.6396 - dense_2_6_loss: 0.7537 - dense_2_7_loss: 0.4878 - dense_2_8_loss: 0.4130 - dense_2_9_loss: 0.5339 - dense_2_10_loss: 0.4851 - dense_2_11_loss: 0.5258 - dense_2_12_loss: 0.6149 - dense_2_13_loss: 0.6658 - dense_2_14_loss: 0.6978 - dense_2_15_loss: 0.4845 - dense_2_16_loss: 0.3230 - dense_2_17_loss: 0.1926 - dense_2_18_loss: 0.0878 - dense_2_19_loss: 0.0293 - dense_2_20_loss: 0.0061 - dense_2_21_loss: 0.0011 - dense_2_22_loss: 2.7953e-04 - dense_2_23_loss: 1.9664e-04 - dense_2_24_loss: 8.7066e-05 - dense_2_accuracy: 0.9616 - dense_2_1_accuracy: 0.9524 - dense_2_2_accuracy: 0.9457 - dense_2_3_accuracy: 0.8853 - dense_2_4_accuracy: 0.8424 - dense_2_5_accuracy: 0.7976 - dense_2_6_accuracy: 0.7628 - dense_2_7_accuracy: 0.8507 - dense_2_8_accuracy: 0.8770 - dense_2_9_accuracy: 0.8375 - dense_2_10_accuracy: 0.8626 - dense_2_11_accuracy: 0.8543 - dense_2_12_accuracy: 0.8284 - dense_2_13_accuracy: 0.8070 - dense_2_14_accuracy: 0.7926 - dense_2_15_accuracy: 0.8599 - dense_2_16_accuracy: 0.9060 - dense_2_17_accuracy: 0.9413 - dense_2_18_accuracy: 0.9721 - dense_2_19_accuracy: 0.9910 - dense_2_20_accuracy: 0.9985 - dense_2_21_accuracy: 0.9998 - dense_2_22_accuracy: 1.0000 - dense_2_23_accuracy: 1.0000 - dense_2_24_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1078/1078 [==============================] - 240s 222ms/step - loss: 5.9187 - dense_2_loss: 0.1142 - dense_2_1_loss: 0.1312 - dense_2_2_loss: 0.1545 - dense_2_3_loss: 0.2944 - dense_2_4_loss: 0.3793 - dense_2_5_loss: 0.4513 - dense_2_6_loss: 0.4733 - dense_2_7_loss: 0.3466 - dense_2_8_loss: 0.3015 - dense_2_9_loss: 0.3492 - dense_2_10_loss: 0.3237 - dense_2_11_loss: 0.3561 - dense_2_12_loss: 0.4262 - dense_2_13_loss: 0.4846 - dense_2_14_loss: 0.4971 - dense_2_15_loss: 0.3532 - dense_2_16_loss: 0.2443 - dense_2_17_loss: 0.1448 - dense_2_18_loss: 0.0657 - dense_2_19_loss: 0.0217 - dense_2_20_loss: 0.0047 - dense_2_21_loss: 8.4987e-04 - dense_2_22_loss: 2.2253e-04 - dense_2_23_loss: 1.5502e-04 - dense_2_24_loss: 7.0341e-05 - dense_2_accuracy: 0.9676 - dense_2_1_accuracy: 0.9643 - dense_2_2_accuracy: 0.9565 - dense_2_3_accuracy: 0.9159 - dense_2_4_accuracy: 0.8860 - dense_2_5_accuracy: 0.8599 - dense_2_6_accuracy: 0.8550 - dense_2_7_accuracy: 0.8958 - dense_2_8_accuracy: 0.9107 - dense_2_9_accuracy: 0.8967 - dense_2_10_accuracy: 0.9096 - dense_2_11_accuracy: 0.9010 - dense_2_12_accuracy: 0.8810 - dense_2_13_accuracy: 0.8633 - dense_2_14_accuracy: 0.8600 - dense_2_15_accuracy: 0.9010 - dense_2_16_accuracy: 0.9293 - dense_2_17_accuracy: 0.9560 - dense_2_18_accuracy: 0.9794 - dense_2_19_accuracy: 0.9937 - dense_2_20_accuracy: 0.9989 - dense_2_21_accuracy: 0.9998 - dense_2_22_accuracy: 1.0000 - dense_2_23_accuracy: 1.0000 - dense_2_24_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1078/1078 [==============================] - 248s 230ms/step - loss: 4.6704 - dense_2_loss: 0.0995 - dense_2_1_loss: 0.1125 - dense_2_2_loss: 0.1322 - dense_2_3_loss: 0.2614 - dense_2_4_loss: 0.3293 - dense_2_5_loss: 0.3721 - dense_2_6_loss: 0.3782 - dense_2_7_loss: 0.2886 - dense_2_8_loss: 0.2542 - dense_2_9_loss: 0.2947 - dense_2_10_loss: 0.2699 - dense_2_11_loss: 0.2883 - dense_2_12_loss: 0.3178 - dense_2_13_loss: 0.3254 - dense_2_14_loss: 0.3260 - dense_2_15_loss: 0.2474 - dense_2_16_loss: 0.1811 - dense_2_17_loss: 0.1149 - dense_2_18_loss: 0.0536 - dense_2_19_loss: 0.0180 - dense_2_20_loss: 0.0039 - dense_2_21_loss: 7.9759e-04 - dense_2_22_loss: 2.6285e-04 - dense_2_23_loss: 1.7072e-04 - dense_2_24_loss: 8.0139e-05 - dense_2_accuracy: 0.9723 - dense_2_1_accuracy: 0.9692 - dense_2_2_accuracy: 0.9608 - dense_2_3_accuracy: 0.9256 - dense_2_4_accuracy: 0.9035 - dense_2_5_accuracy: 0.8893 - dense_2_6_accuracy: 0.8873 - dense_2_7_accuracy: 0.9129 - dense_2_8_accuracy: 0.9252 - dense_2_9_accuracy: 0.9120 - dense_2_10_accuracy: 0.9244 - dense_2_11_accuracy: 0.9202 - dense_2_12_accuracy: 0.9151 - dense_2_13_accuracy: 0.9178 - dense_2_14_accuracy: 0.9169 - dense_2_15_accuracy: 0.9343 - dense_2_16_accuracy: 0.9492 - dense_2_17_accuracy: 0.9656 - dense_2_18_accuracy: 0.9836 - dense_2_19_accuracy: 0.9946 - dense_2_20_accuracy: 0.9990 - dense_2_21_accuracy: 0.9998 - dense_2_22_accuracy: 1.0000 - dense_2_23_accuracy: 1.0000 - dense_2_24_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67f4366940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit([X, s0, c0, out0], outputs, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存参数\n",
    "model.save_weights(\"pretrained_seq2seq_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new jersey is sometimes quiet during autumn , and it is snowy in april .',\n",
       " 'the united states is usually chilly during july , and it is usually freezing in november .',\n",
       " 'california is usually quiet during march , and it is usually hot in june .',\n",
       " 'the united states is sometimes mild during june , and it is cold in september .',\n",
       " 'your least liked fruit is the grape , but my least liked is the apple .',\n",
       " 'his favorite fruit is the orange , but my favorite is the grape .',\n",
       " 'paris is relaxing during december , but it is usually chilly in july .',\n",
       " 'new jersey is busy during spring , and it is never hot in march .',\n",
       " 'our least liked fruit is the lemon , but my least liked is the grape .',\n",
       " 'the united states is sometimes busy during january , and it is sometimes warm in november .',\n",
       " 'the lime is her least liked fruit , but the banana is my least liked .',\n",
       " 'he saw a old yellow truck .',\n",
       " 'india is rainy during june , and it is sometimes warm in november .',\n",
       " 'that cat was my most loved animal .',\n",
       " 'he dislikes grapefruit , limes , and lemons .',\n",
       " 'her least liked fruit is the lemon , but his least liked is the grapefruit .',\n",
       " 'california is never cold during february , but it is sometimes freezing in june .',\n",
       " 'china is usually pleasant during autumn , and it is usually quiet in october .',\n",
       " 'paris is never freezing during november , but it is wonderful in october .',\n",
       " 'the united states is never rainy during january , but it is sometimes mild in october .',\n",
       " 'china is usually pleasant during november , and it is never quiet in october .',\n",
       " 'the united states is never nice during february , but it is sometimes pleasant in april .',\n",
       " 'india is never busy during autumn , and it is mild in spring .',\n",
       " 'paris is mild during summer , but it is usually busy in april .',\n",
       " 'france is never cold during september , and it is snowy in october .',\n",
       " 'california is never cold during may , and it is sometimes chilly in march .',\n",
       " 'he dislikes lemons , grapes , and mangoes.',\n",
       " 'their favorite fruit is the mango , but our favorite is the pear .',\n",
       " 'france is sometimes quiet during may , and it is never chilly in august .',\n",
       " 'paris is never pleasant during september , and it is beautiful in autumn .',\n",
       " 'he dislikes apples , peaches , and grapes .',\n",
       " 'california is usually freezing during december , and it is busy in april .',\n",
       " 'your most feared animal is that shark .',\n",
       " 'paris is usually wet during august , and it is never dry in november .',\n",
       " 'paris is usually beautiful during september , and it is usually snowy in november .',\n",
       " 'the united states is never wet during january , but it is usually hot in october .',\n",
       " 'we like oranges , mangoes , and grapes .',\n",
       " 'they like pears , apples , and mangoes .',\n",
       " 'she dislikes that little red truck .',\n",
       " 'the grapefruit is my most loved fruit , but the banana is her most loved .',\n",
       " 'france is snowy during may , and it is never busy in autumn .',\n",
       " 'china is usually mild during winter , but it is never busy in february .',\n",
       " 'china is never nice during july , but it is usually snowy in spring .',\n",
       " 'california is busy during november , but it is rainy in autumn .',\n",
       " 'china is warm during spring , and it is sometimes cold in february .',\n",
       " 'california is usually beautiful during winter , but it is never busy in february .',\n",
       " 'france is wonderful during november , but it is sometimes hot in september .',\n",
       " 'india is usually pleasant during november , but it is never relaxing in july .',\n",
       " 'the united states is never freezing during autumn , but it is never busy in june .',\n",
       " 'paris is sometimes warm during june , but it is usually hot in july .',\n",
       " 'paris is never hot during summer , and it is usually mild in winter .',\n",
       " 'she disliked a rusty yellow car .',\n",
       " 'france is usually quiet during november , but it is sometimes warm in february .',\n",
       " 'new jersey is never wet during november , and it is mild in august .',\n",
       " 'we like peaches , pears , and strawberries .',\n",
       " 'the orange is her least liked fruit , but the grapefruit is their least liked .',\n",
       " 'china is never rainy during november , and it is quiet in january .',\n",
       " 'china is relaxing during march , but it is sometimes snowy in september .',\n",
       " 'paris is wonderful during march , but it is usually pleasant in june .',\n",
       " 'new jersey is chilly during autumn , and it is sometimes pleasant in spring .',\n",
       " 'california is never freezing during october , but it is usually quiet in june .',\n",
       " 'new jersey is freezing during winter , but it is sometimes wonderful in january .',\n",
       " 'i like grapes , pears , and strawberries .',\n",
       " 'the lemon is my most loved fruit , but the strawberry is our most loved .',\n",
       " 'china is usually dry during march , but it is nice in november .',\n",
       " 'paris is pleasant during december , but it is never nice in november .',\n",
       " 'china is freezing during july , but it is relaxing in january .',\n",
       " 'the apple is our least favorite fruit , but the orange is her least favorite .',\n",
       " 'he dislikes grapes , grapefruit , and bananas.',\n",
       " 'he dislikes apples , mangoes , and strawberries .',\n",
       " 'china is hot during july , but it is never pleasant in january .',\n",
       " 'india is usually dry during april , and it is freezing in february .',\n",
       " 'she is going to the united states next summer .',\n",
       " 'france is sometimes rainy during february , and it is usually quiet in spring .',\n",
       " 'i plan to visit california next may .',\n",
       " 'california is never wet during november , and it is sometimes pleasant in september .',\n",
       " 'they like lemons , limes , and grapefruit .',\n",
       " 'the united states is never beautiful during march , and it is usually relaxing in summer .',\n",
       " 'elephants were his most feared animals .',\n",
       " 'the strawberry is their least favorite fruit , but the apple is our least favorite.',\n",
       " 'they are going to france next june .',\n",
       " 'he likes strawberries , oranges , and limes .',\n",
       " 'california is never pleasant during winter , and it is sometimes wonderful in december .',\n",
       " 'the apple is our least favorite fruit , but the mango is their least favorite .',\n",
       " 'she likes strawberries , oranges , and bananas .',\n",
       " 'california is beautiful during january , and it is pleasant in february .',\n",
       " 'they dislike grapes , mangoes , and limes .',\n",
       " 'she dislikes lemons , grapes , and oranges .',\n",
       " 'our least favorite fruit is the banana , but your least favorite is the grape .',\n",
       " 'california is never cold during december , but it is usually warm in may .',\n",
       " 'california is never busy during february , and it is usually hot in june .',\n",
       " 'the united states is sometimes beautiful during november , and it is never rainy in march .',\n",
       " 'new jersey is sometimes hot during march , and it is beautiful in fall .',\n",
       " 'the grapefruit is our least favorite fruit , but the orange is your least favorite .',\n",
       " 'i like grapefruit , limes , and pears .',\n",
       " 'she dislikes lemons , strawberries , and grapes .',\n",
       " 'paris is usually chilly during fall , but it is sometimes rainy in july .',\n",
       " 'she likes mangoes , apples , and bananas .',\n",
       " 'she is driving the old yellow truck .',\n",
       " 'we like peaches , mangoes , and oranges .']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at source text\n",
    "source_text.split(\"\\n\")[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(sentence):\n",
    "    \"\"\"\n",
    "    对给定的句子进行翻译\n",
    "    \"\"\"\n",
    "    # 将句子分词后转化为数字编码\n",
    "    unk_idx = source_vocab_to_int[\"<UNK>\"]\n",
    "    word_idx = [source_vocab_to_int.get(word, unk_idx) for word in sentence.lower().split()]\n",
    "    \n",
    "    word_idx = np.array(word_idx + [0] * (20 - len(word_idx)))\n",
    "    \n",
    "    # 翻译结果\n",
    "    preds = model.predict([word_idx.reshape(-1,20), s0, c0, out0])\n",
    "    predictions = np.argmax(preds, axis=-1)\n",
    "    \n",
    "    # 转换为单词\n",
    "    idx = [target_int_to_vocab.get(idx[0], \"<UNK>\") for idx in predictions]\n",
    "    \n",
    "    # 返回句子\n",
    "    return \" \".join(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_sentence = input(\"Please input your sentences: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(your_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 可视化Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(sentence, Tx=20, Ty=25):\n",
    "    \"\"\"\n",
    "    可视化Attention层\n",
    "    \n",
    "    @param sentence: 待翻译的句子，str类型\n",
    "    @param Tx: 输入句子的长度\n",
    "    @param Ty: 输出句子的长度\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.array(text_to_int(sentence, source_vocab_to_int))\n",
    "    f = K.function(model.inputs, [model.layers[9].get_output_at(t) for t in range(Ty)])\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    out0 = np.zeros((1, len(target_vocab_to_int)))\n",
    "    \n",
    "    r = f([X.reshape(-1,20), s0, c0, out0])\n",
    "    \n",
    "    attention_map = np.zeros((Ty, Tx))\n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0, t_prime, 0]\n",
    "    \n",
    "    Y = make_prediction(sentence)\n",
    "    \n",
    "    source_list = sentence.split()\n",
    "    target_list = Y.split()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20,15))\n",
    "    sns.heatmap(attention_map, xticklabels=source_list, yticklabels=target_list, cmap=\"YlGnBu\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15, rotation=90)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention(\"she likes mangoes , apples , and bananas .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention(\"california is never pleasant during winter , and it is sometimes wonderful in december .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 BLEU评估\n",
    "\n",
    "采用n-gram的BLEU(Bilingual Evaluation Understudy)来对翻译结果进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个句子的模型翻译结果\n",
    "fr_preds = []\n",
    "\n",
    "# 对样本中的每个英文进行翻译\n",
    "for sentence in tqdm.tqdm(source_text.split(\"\\n\")):\n",
    "    fr_pred = make_prediction(sentence)\n",
    "    # 存储翻译结果\n",
    "    fr_preds.append(fr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以样本中的法语翻译结果为reference\n",
    "references = target_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每个句子的BLEU分数\n",
    "bleu_score = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(fr_preds))):\n",
    "    # 去掉特殊字符\n",
    "    pred = fr_preds[i].replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").rstrip()\n",
    "    reference = references[i].lower()\n",
    "    # 计算BLEU分数\n",
    "    score = sentence_bleu([reference.split()], pred.split())\n",
    "    \n",
    "    bleu_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The BLEU score on our corpus is about {}\".format(sum(bleu_score) / len(bleu_score)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06a52ca9f7de1d000598c3b5b8dbd30de0070d18de6fab21ac0ed6d78647dc91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
